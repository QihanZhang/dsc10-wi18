{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import numpy as np\n",
    "## Normal Distribution\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('fivethirtyeight')\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "voters = Table().with_columns(\"Candidate\", [\"A\", \"B\"], \"Chance\", [0.6, 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def r_scatter(r):\n",
    "    plots.figure(figsize=(5,5))\n",
    "    \"Generate a scatter plot with a correlation approximately r\"\n",
    "    x = np.random.normal(0, 1, 1000)\n",
    "    z = np.random.normal(0, 1, 1000)\n",
    "    y = r*x + (np.sqrt(1-r**2))*z\n",
    "    plots.scatter(x, y)\n",
    "    plots.xlim(-4, 4)\n",
    "    plots.ylim(-4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Confidence Intervals and Sample Size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://inferentialthinking.com/notebooks/san_francisco_2015.csv\n",
    "sf = Table.read_table('san_francisco_2015.csv').select(3, 11, 21)\n",
    "sf.set_format(2, NumberFormatter(0))\n",
    "sf = sf.where(2, are.above(10000))\n",
    "sf.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_bins = np.arange(0, 700000, 25000)\n",
    "sf.hist(2, bins=comp_bins, unit='dollar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# confidence interval methods\n",
    "\n",
    "def bootstrap_mean(sample_from_population, label, repetitions):\n",
    "    resampled_means = []\n",
    "    for i in np.arange(repetitions):\n",
    "        resample = sample_from_population.sample()\n",
    "        mean = np.mean(resample.column(label))\n",
    "        resampled_means.append(mean)\n",
    "    return resampled_means\n",
    "\n",
    "def bootstrap_ci_mean(sample_from_population, label, repetitions):\n",
    "    resampled_means = bootstrap_mean(sample_from_population, label, repetitions)\n",
    "    \n",
    "    interval_95 = make_array(\n",
    "        percentile(2.5, resampled_means),\n",
    "        percentile(97.5, resampled_means)\n",
    "    )\n",
    "    \n",
    "    Table().with_column('Resampled mean', resampled_means).hist(0)\n",
    "    plots.plot(interval_95, [0, 0], color='gold', lw=8)\n",
    "    print('Approximate 95% Bootstrap Confidence Interval for Population Mean:')\n",
    "    print(np.round(interval_95, 3))\n",
    "    print('Interval Width: '+str(interval_95[1] - interval_95[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_sample = sf.sample(200)\n",
    "sf_sample.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resample 1000 times from my original sample (with replacement)\n",
    "#display histogram showing 95% confidence interval\n",
    "\n",
    "bootstrap_ci_mean(sf_sample, 'Total Compensation', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample size was 200. Confidence interval is too wide\n",
    "# Note, numbers will change because samples are random! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What do you think the sample size should be to achieve a \n",
    "# 95% confidence interval with width of $10,000 or less?\n",
    "\n",
    "# A: 250\n",
    "# B: 300\n",
    "# C: 400\n",
    "# D: 800\n",
    "# E: 10,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_sample = sf.sample(800)\n",
    "bootstrap_ci_mean(sf_sample, 'Total Compensation', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#(back to slides to recap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment design\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#potential population\n",
    "\n",
    "votes = [1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
    "np.std(votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "np.std(votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes = [1, 1, 1, 1, 1, 1, 0, 0, 0, 0]\n",
    "np.std(votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_voters=10\n",
    "\n",
    "def sd_voters(n_voters_for_a):\n",
    "    votes = np.append(np.ones(n_voters_for_a), np.zeros(total_voters - n_voters_for_a))\n",
    "    print(votes)\n",
    "    return np.std(votes)\n",
    "\n",
    "sd_voters(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fact: if data contains only 0-1 then SD will never be above 0.5\n",
    "# we know that worst_sd_pop = 0.5\n",
    "# width_in_sds = 4\n",
    "# desired_width = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# √(sample size)  ≥  4 x (SD of 0-1 population) / 0.03\n",
    "worst_sd_pop = 0.5\n",
    "width_in_sds = 4\n",
    "desired_width = 0.03\n",
    "(width_in_sds * (worst_sd_pop / desired_width)) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  no matter what my population looks like, \n",
    "# if I take a sample of 4445 people, my CI will always be 0.03 width or less"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conducting the experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voters.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voters.select(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights - Array specifying probability. Must be a valid probability distribution \n",
    "\n",
    "observed_sample = voters.select(0).sample(1000, weights=voters.column('Chance'))\n",
    "observed_sample.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# means are proportions\n",
    "\n",
    "n = 4445\n",
    "observed_sample = voters.select(0).sample(n, weights=voters.column('Chance'))\n",
    "\n",
    "means = []\n",
    "for i in np.arange(1000):\n",
    "    resample = observed_sample.sample()\n",
    "    means.append(np.count_nonzero(resample.column(0) == 'A') / n) \n",
    "    \n",
    "print(percentile(2.5, means), percentile(97.5, means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.6161979752530934 - 0.5808773903262092"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reminder:\n",
    "\n",
    "#http://inferentialthinking.com/notebooks/galton.csv\n",
    "galton = Table.read_table('galton.csv')\n",
    "\n",
    "\n",
    "\n",
    "heights = Table().with_columns(\n",
    "    'MidParent', galton.column('midparentHeight'),\n",
    "    'Child', galton.column('childHeight')\n",
    "    )\n",
    "\n",
    "heights.scatter(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "\n",
    "def predict_child(parent):\n",
    "    \"\"\"Return a prediction of the height of a child \n",
    "    whose parents have a midparent height of parent.\n",
    "    \n",
    "    The prediction is the average height of the children \n",
    "    whose midparent height is in the range mpht plus or minus 0.5 inches.\n",
    "    \"\"\"\n",
    "    close_points = heights.where('MidParent', are.between(parent - 0.5, parent + 0.5))\n",
    "    return close_points.column('Child').mean()\n",
    "\n",
    "heights_and_predict = heights.with_column(\n",
    "    'Prediction', heights.apply(predict_child, 'MidParent')\n",
    ")\n",
    "\n",
    "heights_and_predict.scatter(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Goal: perfect straight line instead of wiggly yellow curve\n",
    "\n",
    "# Variables need to be related to be able to predict one from the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://inferentialthinking.com/notebooks/hybrid.csv\n",
    "hybrid = Table.read_table('hybrid.csv')\n",
    "hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do you expect to see an association between acceleration and price? What kind of association? \n",
    "\n",
    "hybrid.scatter('acceleration', 'msrp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"image1.png\", width=800, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Do you expect to see an association between mpg and price? What kind of association? \n",
    "\n",
    "hybrid.scatter('mpg', 'msrp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This one looks less like a line, more curved.\n",
    "# When observing whether there is an association, and whether that association is linear, \n",
    "# we only look at shape of points, not the units on the axes.\n",
    "# To be more general, use standard units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper methods:\n",
    "\n",
    "def standard_units(any_numbers):\n",
    "    \"Convert any array of numbers to standard units.\"\n",
    "    return (any_numbers - np.mean(any_numbers)) / np.std(any_numbers)  \n",
    "\n",
    "def standardize(t):\n",
    "    \"\"\"Return a table in which all columns of t are converted to standard units.\"\"\"\n",
    "    t_su = Table()\n",
    "    for label in t.labels:\n",
    "        t_su = t_su.with_column(label + ' (su)', standard_units(t.column(label)))\n",
    "    return t_su\n",
    "\n",
    "hybrid_su = standardize(hybrid.select('msrp', 'acceleration','mpg'))\n",
    "hybrid_su"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_su.scatter('acceleration (su)', 'msrp (su)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_su.scatter('mpg (su)', 'msrp (su)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Notice the shapes are the same, so we can do all our analysis in standard units, to be very general.\n",
    "\n",
    "# One of these still looks more like a line than the other - can we make that more precise? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"image2.png\", width=600, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try out different values of r\n",
    "\n",
    "r_scatter(0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"image5.png\", width=800, height=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Image(\"image6.png\", width=800, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Then compute the average of the rightmost column -> 0.617\n",
    "\n",
    "# Positive association: below-average values of x usually go with below-average values of y\n",
    "# and sign of the product is usually positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correlation(t, label_x, label_y):\n",
    "    return np.mean(standard_units(t.column(label_x))*standard_units(t.column(label_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid.scatter('acceleration', 'msrp')\n",
    "correlation(hybrid, 'acceleration', 'msrp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hybrid.scatter('mpg', 'msrp')\n",
    "correlation(hybrid, 'mpg', 'msrp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We know how to make predictions regardless of correlation (as we did with Galton's data).\n",
    "\n",
    "# Correlation tells you something about accuracy of your predictions:\n",
    "# higher magnitude (absolute value) of correlation means more accurate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"image4.png\", width=600, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Important: Not correlated does not mean not related. \n",
    "# First visualize, then quantify "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Back to Galton's data\n",
    "\n",
    "#Trying to discover equation for yellow curve - would like a perfect line\n",
    "\n",
    "heights_and_predict.scatter(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How strong is the linear trend?\n",
    "\n",
    "correlation(heights_and_predict, 'MidParent', 'Child')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We take our heights and convert them to standard units:\n",
    "\n",
    "standardize(heights).scatter(0)\n",
    "plots.xlim(-4, 4)\n",
    "plots.ylim(-4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# When converting to standard units, only axes change, shape is same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a natural line of symmetry, 45 degree angle - is this a good prediction line?\n",
    "\n",
    "standardize(heights).scatter(0)\n",
    "plots.xlim(-4, 4)\n",
    "plots.ylim(-4, 4)\n",
    "plots.plot([-4, 4], [-4, 4], color='r', lw=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# green line: drawn at particular x value that I want to predict\n",
    "\n",
    "standardize(heights).scatter(0)\n",
    "plots.xlim(-4, 4)\n",
    "plots.ylim(-4, 4)\n",
    "plots.plot([-4, 4], [-4, 4], color='r', lw=2)\n",
    "plots.plot([2.5, 2.5], [-4, 4], color='g', lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#blue line goes through centers of vertical strips - it is flatter\n",
    "\n",
    "standardize(heights).scatter(0)\n",
    "plots.xlim(-4, 4)\n",
    "plots.ylim(-4, 4)\n",
    "plots.plot([-4, 4], [-4, 4], color='r', lw=2)\n",
    "plots.plot([2.5, 2.5], [-4, 4], color='g', lw=2)\n",
    "\n",
    "r = correlation(heights, 0, 1)\n",
    "plots.plot([-4, 4], [-4*r, 4*r], color='dodgerblue', lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# notice that blue and red lines both go through (0,0)\n",
    "\n",
    "# What is slope of blue line? \n",
    "\n",
    "# Positive or negative? \n",
    "\n",
    "# More or less than one?\n",
    "\n",
    "# blue line is called a regression line, goes through middle points\n",
    "\n",
    "# Can you find equation of a line that goes through origin with a given slope?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"image3.png\", width=700, height=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Consider height of child whose parents are extremely tall\n",
    "\n",
    "# (back to slides - graph of averages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Line for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: How does the regression line compare to our original prediction?\n",
    "\n",
    "heights_and_predict.scatter(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = correlation(heights_and_predict, 'MidParent', 'Child')\n",
    "parent_mean = np.mean(heights.column('MidParent'))\n",
    "parent_sd = np.std(heights.column('MidParent'))\n",
    "child_mean = np.mean(heights.column('Child'))\n",
    "child_sd = np.std(heights.column('Child'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_with_r(parent):\n",
    "    \"\"\"Return a prediction of the height of a child \n",
    "    whose parents have a midparent height of parent, \n",
    "    using linear regression.\n",
    "    \"\"\"\n",
    "    parent_su = (parent - parent_mean) / parent_sd\n",
    "    child_su = r * parent_su\n",
    "    return child_su * child_sd + child_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parent -> child (below the parents' height)\n",
    "\n",
    "predict_with_r(68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parent -> child (below the parents' height)\n",
    "\n",
    "predict_with_r(74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parent -> child \n",
    "\n",
    "predict_with_r(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now with all the midparent heights\n",
    "\n",
    "heights_and_predict.with_column(\n",
    "    'Prediction with r', \n",
    "    heights_and_predict.apply(predict_with_r, 'MidParent')).scatter(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#(back to slides - slope and intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slope and Intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How to work in original units?\n",
    "\n",
    "def correlation(t, x, y):\n",
    "    return np.mean(standard_units(t.column(x))*standard_units(t.column(y)))\n",
    "\n",
    "def slope(t, x, y):\n",
    "    \"\"\"The slope of the regression line (original units)\"\"\"\n",
    "    r = correlation(t, x, y)\n",
    "    return r * np.std(t.column(y)) / np.std(t.column(x))\n",
    "\n",
    "def intercept(t, x, y):\n",
    "    \"\"\"The intercept of the regression line (original units)\"\"\"\n",
    "    return np.mean(t.column(y)) - slope(t, x, y) * np.mean(t.column(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid.scatter('acceleration', 'msrp', fit_line = True)\n",
    "\n",
    "# Make predictions with the line y=ax+b\n",
    "\n",
    "a = slope(hybrid, 'acceleration', 'msrp')\n",
    "b = intercept(hybrid, 'acceleration', 'msrp')\n",
    "\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the retail price of a hybrid with acceleration of 12.5\n",
    "\n",
    "a*12.5+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
