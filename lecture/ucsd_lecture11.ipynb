{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 300\n",
    "serialno = Table().with_column('Serial number', np.arange(1, 300))\n",
    "serialno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialno.sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialno.sample(30).column(0).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repetitions = 1000\n",
    "sample_size = 30\n",
    "maxes = make_array()\n",
    "for i in np.arange(repetitions):\n",
    "    m = serialno.sample(sample_size).column(0).max()\n",
    "    maxes = np.append(maxes, m)\n",
    "maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates = Table().with_column(\"estimated_N\", maxes)\n",
    "estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates.hist(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates.hist(0, bins = np.arange(1, 400, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# back to slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repetitions = 1000\n",
    "sample_size = 30\n",
    "maxes = make_array()\n",
    "doubles = make_array()\n",
    "\n",
    "for i in np.arange(repetitions):\n",
    "    sample = serialno.sample(sample_size).column(0)\n",
    "    maxes = np.append(maxes, sample.max())\n",
    "    doubles = np.append(doubles, np.average(sample)*2)\n",
    "\n",
    "estimates = Table().with_columns(\"largest # seen\", maxes, '2*average', doubles)\n",
    "estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates.hist(bins = np.arange(1, 400, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#back to slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Bias and Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we come up with a new estimate that's less biased than the largest number seen, and less variable than twice the average?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clever Esimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "N = 300\n",
    "serialno = Table().with_column('Serial number', np.arange(1, 300))\n",
    "serialno\n",
    "\n",
    "repetitions = 1000\n",
    "sample_size = 30\n",
    "maxes = make_array()\n",
    "doubles = make_array()  # 2*np.average(observation)\n",
    "max_plus_min = make_array()  #max plus  min values from the sample\n",
    "\n",
    "\n",
    "for i in np.arange(repetitions):\n",
    "    sample = serialno.sample(sample_size).column(0)\n",
    "    maxes = np.append(maxes, sample.max())\n",
    "    doubles = np.append(doubles, np.average(sample)*2)\n",
    "    max_plus_min = np.append(max_plus_min, sample.max()+sample.min())\n",
    "\n",
    "\n",
    "estimates = Table().with_columns(\"largest # seen\", maxes, '2*average', doubles, 'max+min', max_plus_min)\n",
    "estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates.hist(bins = np.arange(1, 400, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#back to slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jury selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11 felony trials and 1453 poeple who reported for jury service\n",
    "# Looked at the ethnic composition of those 1453 people\n",
    "# as compared to the ethnic composition of eligible jurors \n",
    "\n",
    "# We are going to look at these two distributions and compare them. \n",
    "# Column \"Eligible\": proportions in the eligible population (elaborate later) \n",
    "# Column \"Panel\": among 1453 people these are the distributions. \n",
    "\n",
    "\n",
    "jury = Table().with_columns(\n",
    "    'Ethnicity', make_array('Asian', 'Black', 'Latino', 'White', 'Other'),\n",
    "    'Eligible', make_array(0.15, 0.18, 0.12, 0.54, 0.01),\n",
    "    'Actual', make_array(0.26, 0.08, 0.08, 0.54, 0.04)\n",
    ")\n",
    "\n",
    "jury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to compare:\n",
    "\n",
    "jury.barh('Ethnicity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#What ethnicities were under-represented based on the bar chart above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Main question: If you select at random from blue distribution, you do not expect to get exactly blue distribution,\n",
    "#it will be off. Is the random selection off like a random sample would be off? Or is it off in some other way?\n",
    "\n",
    "#Let's quantify word \"OFF\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure of the difference between two distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment the table with a column of differences between proportions\n",
    "\n",
    "jury_with_diffs = jury.with_column(\n",
    "    'Difference', jury.column('Actual') - jury.column('Eligible')\n",
    ")\n",
    "jury_with_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. Exercise for you: Add the positive differences and then add the negative differences\n",
    "\n",
    "# Reason: (x1-y1) + (x2-y2) + (x3-y3) + (x4-y4) = 0\n",
    "#         (x1 + x2 + x3 + x4) - (y1 + y2 + y3 + y4) = 1 - 1 =0. \n",
    "\n",
    "# 2. Therefore, averaging the distances does not make sense. \n",
    "\n",
    "# 3. 0.14 is a measure of the distance between the two. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To avoid the cancellation, we drop the negative signs\n",
    "\n",
    "jury_with_diffs = jury_with_diffs.with_column(\n",
    "    'Abs. Difference', np.abs(jury_with_diffs.column('Difference'))\n",
    ")\n",
    "\n",
    "jury_with_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#then you add them up and divide by 2:\n",
    "#total variation distance between the two distributions\n",
    "#(back to slides)\n",
    "\n",
    "jury_with_diffs.column('Abs. Difference').sum()/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#takes two arrays (with distributions)\n",
    "#returns total variation distance between them\n",
    "\n",
    "def total_variation_distance (distribution_1, distribution_2):\n",
    "    '''Function that computes total variation distance between two arrays'''\n",
    "    return np.abs(distribution_1-distribution_2).sum()/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#what is the purpose of this function?\n",
    "\n",
    "def table_tvd(table, label, other_label):\n",
    "    '''What does it do?'''\n",
    "    return total_variation_distance(table.column(label),table.column(other_label))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What answer do you expect?\n",
    "table_tvd(jury, 'Eligible', 'Actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step back: What was our goal?\n",
    "# Please, talk to each other to come up with a plan to achieve this goal.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "panel_size = 1453"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#proportions_from_distribution method is defined for you\n",
    "panels_and_sample = proportions_from_distribution(jury, 'Eligible', panel_size)\n",
    "panels_and_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this function do? According to the documentation, \n",
    "\n",
    "### proportions_from_distribution(table, label, sample_size, column_name='Random Sample')\n",
    "\n",
    "Adds a column named column_name containing the proportions of a random draw using the distribution in label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panels_and_sample.barh('Ethnicity')\n",
    "#what you see here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we are going to simulate the total variation distance \n",
    "#between distribution of eligible jurors and a random sample from that distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_tvd(panels_and_sample, 'Eligible', 'Random Sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same thing, many times\n",
    "\n",
    "panel_size = 1453\n",
    "repetitions = 5000\n",
    "\n",
    "tvds = make_array()\n",
    "\n",
    "for i in np.arange(repetitions):\n",
    "\n",
    "    new_sample = proportions_from_distribution(jury, 'Eligible', panel_size)\n",
    "    tvds = np.append(tvds, table_tvd(new_sample, 'Eligible', 'Random Sample'))\n",
    "\n",
    "results = Table().with_column('TVD', tvds)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.hist(bins=np.arange(0, 0.2, 0.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#back to slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# San Francisco Employee Incomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'san_francisco_2015.csv' # 'http://inferentialthinking.com/notebooks/san_francisco_2015.csv'\n",
    "\n",
    "sf = Table.read_table(data).select(3, 11, 21)\n",
    "sf.set_format(2, NumberFormatter(0))\n",
    "sf = sf.where(2, are.above(10000))\n",
    "sf.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.sort(2, descending  =  True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_bins = np.arange(0, 700000, 25000)\n",
    "sf.hist(2, bins=comp_bins, unit='dollar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#suppose we only have access to the sample:\n",
    "\n",
    "sample_from_population = sf.sample(200, with_replacement=False)  #unique workers \n",
    "sample_from_population.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the median compensation in the population? Presumably, you do not know it. \n",
    "np.median(sample_from_population.column(2))\n",
    "\n",
    "# Is this median accurate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#back to slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aside: lists and append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = make_array(2, 3, 4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.append(a, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [2, 3, 4]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this append is different from np.append \n",
    "b.append(5)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop in order to see the variation of the medians. \n",
    "\n",
    "medians = []\n",
    "repetitions = 100\n",
    "\n",
    "for i in np.arange(repetitions):\n",
    "    sample_from_population = sf.sample(200, with_replacement=False)\n",
    "    medians.append(np.median(sample_from_population.column(2)))\n",
    "\n",
    "Table().with_columns(\n",
    "    'i', np.arange(100),\n",
    "    'median', medians,\n",
    ").scatter('i')\n",
    "\n",
    "\n",
    "#what do you see on this scatter plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#(back to slides)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "name": "_merged_merged"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
