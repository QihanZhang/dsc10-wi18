{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 2 - PAC Learning\n",
    "\n",
    "Due: Thursday, Nov 2 at 11:59pm\n",
    "\n",
    "You may work alone or with one partner using pair programming. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, you will use the Probably Approximately Correct Learning model to learn the concept of \"typical air pollution\" in California.\n",
    "\n",
    "Our data set comes from the Center for Disease Control's online database, WONDER (Wide-ranging OnLine Data for Epidemiologic Research). A description of the data set from WONDER is given below: \n",
    "\n",
    "\"The Outdoor Air Quality - Fine Particulate Matter data available on CDC WONDER are geographically aggregated daily measures of fine particulate matter in the outdoor air, spanning the years 2003-2011. PM2.5 particles are air pollutants with an aerodynamic diameter less than 2.5 micrometers. Reported measures are the daily measure of fine particulate matter in micrograms per cubic meter (PM2.5) (µg/m³), the number of observations, minimum and maximum range value, and standard deviation. Data are available by place (combined 48 contiguous states plus the District of Columbia, region, division, state, county), time (year, month, day) and specified fine particulate matter (µg/m³)value. County-level and higher data are aggregated from 10 kilometer square spatial resolution grids.\" Source: https://wonder.cdc.gov/wonder/help/PM.html#\n",
    "\n",
    "For this project, we have selected a single measurement for each day from 2003 to 2011: the average measurement of fine particulate matter in California air. This measurement ranges from 0 µg/m³ to 65 µg/m³, and is reported to two decimal places. Note that a measurement of over 65 µg/m³ is reported as 65 µg/m³. Each measurement is given a label as typical or not. A value of 1 in the column \"Typical?\" indicates that this a typical measurement of air quality, not exceptionally large or exceptionally small. A value of 0 indicates an atypical measurement. \n",
    "\n",
    "Data Source: Daily Fine Particulate Matter (PM2.5) (µg/m³) for years 2003-2011 on CDC WONDER Online Database, released 2013. Accessed at http://wonder.cdc.gov/NASA-PM.html on Oct 22, 2017 4:20:23 PM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Don't change this cell; just run it. \n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('project2.ok')\n",
    "_ = ok.auth(inline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell to submit your code. You can always resubmit before the deadline.\n",
    "_ = ok.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "#  Note: these are all the imports you need! Do not import any other functions / packages\n",
    "%matplotlib inline\n",
    "\n",
    "from datascience import *\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the table of labeled data.\n",
    "air = Table.read_table('california_air_quality.csv')\n",
    "air"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "We decide to use just 10 of our labeled data points to train the model, and the rest of our data to test the model. Make a table called 'train' that contains a random selection of 10 of the rows of the table 'air'. Make a table called 'test' that contains the remaining rows of the table 'air'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_size = 10\n",
    "train = ...\n",
    "test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 \n",
    "\n",
    "The learner's goal is to determine which values of Average Fine Particulate Matter are considered typical.  The learner's hypothesis will be in the form of two numbers, which we will call 'left_endpoint' and 'right_endpoint'.\n",
    "The closed interval from 'left_endpoint' to 'right_endpoint' (which includes both endpoints) is the learner's guess of what constitutes a typical value of air quality. \n",
    "\n",
    "Use the data in the table 'train' to develop a hypothesis of this form. If you are having trouble, look at the ten data points in 'train' and come up with your own guess for what it means for the air pollution to be typical. How did you do it?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_endpoint = ...\n",
    "right_endpoint = ...\n",
    "\n",
    "print(\"The hypothesis is that all values between \" + str(left_endpoint) + \" and \" + str(right_endpoint) + \" are typical.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "What percentage of the training data falls between 'left_endpoint' and 'right_endpoint' (inclusive)? Is this percentage a measurement of the accuracy of your hypothesis? Why or why not?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of training data that falls in the interval\n",
    "\n",
    "percentage = ...\n",
    "percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this text with your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "Use your hypothesis to predict the label for each point in the test set (the table 'test'). Compare this hypothesized label to the actual label and compute the accuracy as the percentage of test points correctly labeled by the hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function that takes as input an Average Fine Particulate Matter value, \n",
    "# and returns 1 if the value is between 'left_endpoint' and 'right_endpoint' (inclusive) \n",
    "# and 0 otherwise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = ...\n",
    "print(\"The hypothesis is correct on \" + str(accuracy) +\" percent of the test data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "You want to increase the accuracy of your prediction by using a bigger test set. Try the entire process again using various values of 'training_size.' Try 10 points, 20, 30, 40, and every multiple of 10 up to 3000, using a for loop and copying the relevant code from the questions above. Display your results in a table called 'results' that contains four columns, the size of the training set, the value of 'left_endpoint', the value of 'right_endpoint' and the accuracy of the hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ...\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "You would expect that with more training points, the prediction would be more accurate. Is that what happens, according to your 'results' table? Explain why, using the idea of \"probably approximately correct.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this text with your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell to submit your code. You can always resubmit before the deadline.\n",
    "_ = ok.submit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
